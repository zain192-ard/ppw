DOI,Title,Abstract,URL
10.1007/978-3-031-90470-7_6,‘Internet of Things’ and ‘Social Networking’: Containment,"Moving to the post-2000 period, or the post-formation Internet Polity, this chapter begins with the implications of the internet becoming the centred repository of sources, medium of investigation, and object in historicist accounts of recent and contemporary events. Debates on ‘technological determinism Technological determinism ’ are considered here. As events, 9/11 and the 2000 dot-com crash are pegged as turning points. A broad argument is proposed about the condition of the Internet Polity thereafter. It is suggested that it became contained in two moves during the 2000s. This containment involved, first, a space of the internet opening beyond the scope of the Internet Polity. This space incorporated data exchanges between ‘smart’ objects, unsupervised systems, and machine-learning systems. Second, much of the Internet Polity discourse and collective life became concentrated in very large platforms, which have global reach, local penetration, and data-management standards. This move facilitated the burgeoning data market and fed into the first move. The two moves are outlined by focusing on two catchwords and related terms. The first is addressed via the connotations of ‘Internet of Things’ and ‘smart’ objects, and the second by pausing on ‘social networking’ (on ‘sites’ or ‘platforms’). This chapter, and the study, concludes by briefly reconsidering the formative first principles of the Internet Polity, and pinpointing areas for further investigations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-90470-7_6
10.1007/978-3-032-00983-8_5,Survey on Data Mining and Machine Learning Methods Used in Analyzing Tweets,"It is observed that the Mental illness by the actions and individual emotions and expressions towards a particular situation. It indicates that American Psychiatric Association that has 19% of people experience mental illness. Nearly 4.1% of people [ 1 ] are seriously affected by mental illness. In 2019, World Health Organization(WHO) reported that 264 million people suffer from mental disorders. With the technological growth and affordable internet access, social media usage and impacts are increased in society. Users use social networks to show their emotions, views, and comments related to mental health on various events and themselves. Different intelligent methods that analyze tweets related to depression are summarized. New research areas in analyzing data on social networks are discussed. This article highlights the data mining and machine learning methods associated with mental health using Twitter data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-00983-8_5
10.1007/978-3-031-93802-3_7,Unveiling Power Laws in Graph Mining: Techniques and Applications in Graph Query Analysis,"Power laws play a crucial role in understanding the structural and functional properties of real-world graphs, influencing various aspects of graph mining and query processing. This paper explores the prevalence of power-law distributions in large-scale graph structures and their implications for graph query analysis. We investigate techniques for efficiently mining graphs that exhibit power-law characteristics, leveraging these distributions to optimize query performance and scalability. Our study presents a comprehensive review of existing methodologies for detecting power-law behavior in graphs, highlighting their impact on graph traversal, indexing, and query execution. We also examine algorithmic optimizations tailored for power-law graphs, including degree-based indexing, community-aware search techniques, and efficient subgraph matching approaches. Furthermore, we discuss the applications of power-law principles in diverse domains such as social network analysis, bioinformatics, and knowledge graphs. Through empirical analysis on real-world datasets, we demonstrate how power-law-aware techniques improve query efficiency and reduce computational complexity in large graph databases. The findings of this study offer valuable insights into the interplay between graph topology and query optimization, paving the way for enhanced graph mining frameworks. Our work contributes to the development of more scalable and intelligent graph query processing systems, with broad implications for data-driven decision-making.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-93802-3_7
10.1007/978-3-032-02215-8_7,An Enhanced FP-Growth Algorithm with Hybrid Adaptive Support Threshold for Association Rule Mining,"Finding frequent itemsets remains challenging due to manual threshold specification requirements in existing algorithms. This paper presents an Enhanced FP-Growth algorithm incorporating a hybrid adaptive support threshold that combines statistical variance analysis, frequency distribution patterns, and transaction density metrics. The algorithm automatically adjusts support levels based on dataset characteristics, eliminating manual threshold tuning. Experimental evaluation on five benchmark datasets against Aprior, FP-growth, and FP-Max shows our Enhanced FP-Growth consistently achieves superior execution time and improved memory efficiency. The hybrid threshold mechanism dynamically calibrates according to dataset characteristics, offering substantial efficiency gains across diverse data types.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02215-8_7
10.1007/978-3-032-04207-1_24,An Empirical Analysis on the Use of Third-Party HTTP Clients in Open-Source Java Projects,"External communication libraries (e.g., for HTTP/REST) are static dependencies that enable dynamic dependencies in software systems. Such third-party HTTP libraries may influence the system’s qualities. Thus, the selection out of numerous third-party HTTP clients needs to be taken carefully. However, the use of such clients has not been studied broadly. We conduct a quantitative empirical study of 18,879 open-source Java repositories and analyze 259,683 configuration files. We further investigate a subset of these repositories qualitatively and in more depth. We have found that Apache HttpClient, Spring Web, and OkHttp are the most used third-party HTTP clients in Java open-source projects. Further analysis has shown that declared dependencies are often not actively managed, reference outdated versions, or are entirely unused.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-04207-1_24
10.1007/978-3-031-93257-1_6,Adaptive Web API Recommendation via Matching Service Clusters and Mashup Requirement,"With the rapid proliferation of Web services and Web APIs, recommendation systems can effectively address the issue of information overload and alleviate the burden of meaningless filtering. Existing approaches can help filtering appropriate Web services for mashup creation, however, they often fall short of developers’ different and personalized needs by recommending only a fixed number of APIs and lack precision in aligning mashup requirements across all categories. To solve the above issue, this paper introduces a novel Web service recommendation framework called AWAR for mashup creation, which focuses on the matching strategy between mashup requirements and Web APIs, and enhances recommendation effectiveness by integrating natural language processing, optimization algorithms, and deep learning. Extensive experiments conducted on large-scale real datasets demonstrate that the proposed approach receives superior recommendation results on multiple evaluation metrics compared to advanced competing baselines.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-93257-1_6
10.1007/978-3-032-02088-8_29,Benchmarking Embedding Techniques for Modeling User Navigation Behavior on Task-Oriented Software,"Understanding user navigation patterns from clickstream data is crucial for improving business software, yet remains challenging due to the complexity and variability of real-world environments. Unlike controlled settings, real-world clickstreams are noisy, fragmented, and often incomplete, due to session timeouts, network issues, caching, or third-party interactions—making it difficult to reconstruct coherent user journeys. Additionally, the absence of labeled data hinders the use of supervised learning, pushing researchers toward unsupervised or heuristic-based approaches that struggle to fully capture user behavior. In this paper, we present a benchmark of embedding techniques for modeling user navigation behavior on task-oriented software. We identify distinct user behaviors across three real-world case studies. Results show that Pattern2Vec outperforms Word2Vec in capturing meaningful task-based navigation patterns, confirming its suitability for clickstream analysis.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02088-8_29
10.1007/978-3-032-04200-2_27,What Do We Know About Software Analytics Research? A Critical Review of Secondary Studies,"Software analytics (SA) is often proposed as a tool to support software engineering (SE) tasks. Several secondary studies on SA have been published, some published within the same calendar year. This presents an opportunity to take a meta-perspective and examine how the field of SA has been conceptualized and synthesized so far. By analyzing how SA is defined, which topics are emphasized, what search strategies are employed, and to what extent primary studies overlap, we aim to identify gaps, trends, and redundancies in the current body of secondary studies. Such insights can inform the design and focus of future secondary studies. We identified five secondary studies on SA published from 2015 to 2023 that cover primary research from 2000 to 2021. Despite similarities in objectives and overlapping search timeframes, the secondary studies have negligible overlap in their included primary studies. Each secondary study presents a distinct perspective, and collectively, the five secondary studies offer a fragmented rather than cohesive view of the research landscape. We present a structured overview of the identified secondary studies in terms of their objectives, research quality, and findings. This overview helps readers navigate and leverage existing research. The analysis also indicates that there is potential for further secondary research to build a more cohesive and comprehensive understanding of the SA literature.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-04200-2_27
10.1007/978-3-032-04207-1_14,DevScholar: A Reuse-Based Approach for Evaluating Developer Contribution,"Evaluating each developer’s contributions within collaborative software projects is essential for effective resource allocation, recognition of expertise, and identifying training needs. Traditional metrics such as lines of code (LOCs) or the number of commits fail to provide a comprehensive context since code varies in importance and complexity. On the other hand, writing reusable code is an essential coding practice that can serve as a metric for measuring the quality of the developers’ contributions. Our goal is to develop a methodology and a practical tool for evaluating developers’ reusable code contributions within a software project. Drawing inspiration from Hirsch’s H-Index, a benchmark metric in academia, we constructed the Developer H-Index (DH-Index). It tracks each method’s usage throughout the project identified via call graphs akin to citations in academic research and links these references to the respective developer contributions. We also created a variation of the DH-Index that weighs method usage with the Lines-of-Code-Weighted Developer H-Index (LWDH-Index). We developed DevScholar, a publicly available prototype that extracts and analyzes method-based contributions from software developers of a Java project. We compared our tool’s capabilities with GitHub Insights on four Open Source Software (OSS) projects, Apollo, Spring Boot, Retrofit, and Dubbo but only presenting the results of Apollo project. LWDH-Index resulted in a stronger metric, as it smoothed out the effect of the disproportionate contribution of frequently called methods that are too simple and of rarely called methods that are too long. In conclusion, compared to simple metrics based only on LOC or the number of commits, the DH-Index and LWDH-Index offer additional perspectives for evaluating developers’ contributions to reusable code within a software project team.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-04207-1_14
10.1007/978-3-032-01723-9_9,Analyzing Water Consumption Patterns in Mexico City: A GIS and Data Science Approach,"Water scarcity in Mexico City has become an increasingly urgent issue, exacerbated by inefficient and unequal consumption patterns across its urban fabric. This study advances Geographic Information Systems (GIS) research by developing and applying an integrative spatial analysis framework specifically tailored to the complexities of urban water management. Beyond its application to Mexico City, the research demonstrates how GIS can be used to fuse heterogeneous datasets, including those from SACMEX (Mexico City’s Water System), INEGI (National Institute of Statistics and Geography), and DENUE (National Directory of Economic Units), into a unified analytical environment. Through a combination of exploratory data analysis (EDA), spatial data mining, and clustering techniques, the study identifies critical disparities in water consumption at multiple spatial scales, from boroughs to neighborhoods. A key contribution is the implementation of a layered system architecture for managing historic spatiotemporal data, enabling dynamic visualization of consumption patterns. The findings reveal that socio-economic and demographic variables play a decisive role in shaping spatial water demand, with marginalized communities facing disproportionate challenges. While previous spatiotemporal analyses of water consumption in Mexico City have primarily focused on aggregated borough-level data or isolated socio-demographic correlations, they have often lacked multiscale integration, high-resolution neighborhood-level analysis, or interactive visualization tools to support policy development. This research addresses these limitations by providing a fine-grained, multilayered analytical approach that enhances the scientific understanding of urban water use. Beyond offering immediate policy-relevant insights for Mexico City, the methodological framework proposed here contributes to GIS research by providing a scalable, transferable approach for analyzing urban resource consumption patterns. Future work will focus on incorporating real-time data streams, expanding sector-specific analysis, and integrating additional variables and domains required for a comprehensive understanding of water dynamics. This study represents a first step toward building an adaptive, equitable, and efficient urban water management strategy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-01723-9_9
